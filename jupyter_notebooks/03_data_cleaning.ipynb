{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data Cleaning\n",
    "\n",
    "ps: *Don't forget Garbage In, Garbage out.*"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Objectives:\n",
    "\n",
    "Our objectives for this notebook are as following:\n",
    "\n",
    "- Prepare the data sets for further analysis.\n",
    "- Load and inspect the data prepared during data collection.\n",
    "- Correlation and PPS study.\n",
    "- Data Cleaning.\n",
    "- Conclusion and next steps.\n",
    "\n",
    "\n",
    "## Inputs:\n",
    "\n",
    "- inputs/datasets/raw/house-price-20211124T154130Z-001/house-price/house_prices_records.csv\n",
    "- inputs/datasets/raw/house-price-20211124T154130Z-001/house-price/refurbished_houses.csv\n",
    "\n",
    "\n",
    "## Outputs:\n",
    "\n",
    "- outputs/datasets/cleaned/train_set.csv\n",
    "- outputs/datasets/cleaned/test_set.csv\n",
    "- outputs/datasets/cleaned/clean_house_price_records.csv\n",
    "- outputs/datasets/cleaned/clean_refurbished_houses.csv\n",
    "\n",
    "### Additional Comments:\n",
    "\n",
    "- As previously mentioned this projects relays on the guidelines provided in the walk through projects, and the lessons provided along the course (especially in the Predictive Analysis)\n",
    "- Therefore, this notebook will be relating the Data Preparation step of Crisp-DM methodology. \n",
    "\n",
    "___\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Change working directory.\n",
    "\n",
    "- Change the working directory from its current folder to its parent folder: \n",
    "    - Access the current directory with os.getcwd()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "current_dir = os.getcwd()\n",
    "current_dir"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Make the parent of the current directory the new current directory:\n",
    "\n",
    "- os.path dirname() gets the parent directory.\n",
    "- os.chir() defines the new current directory."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "os.chdir(os.path.dirname(current_dir))\n",
    "print(\"You set a new current directory, well done!\")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Confirm the new current directory:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "current_dir = os.getcwd()\n",
    "current_dir"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "___"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Import the necessary packages and set environmental variables:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "pd.options.display.max_columns = None\n",
    "from pandas_profiling import ProfileReport\n",
    "from feature_engine.imputation import ArbitraryNumberImputer, CategoricalImputer\n",
    "from sklearn.pipeline import Pipeline"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Load the data downloaded in the data collection notebook:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv(f\"inputs/datasets/raw/house-price-20211124T154130Z-001/house-price/house_prices_records.csv\")\n",
    "print(df.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_refurbished = pd.read_csv(f\"inputs/datasets/raw/house-price-20211124T154130Z-001/house-price/refurbished_houses.csv\")\n",
    "print(df_refurbished.shape)\n",
    "df_refurbished"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "____"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data Exploration\n",
    "\n",
    "- We need to explore the dataset, check variable types and distributing, missing levels and what value these variables my add in the content of the first business requirement. "
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- First we will need to list the variables that are missing a value: "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "vars_missing_data = df.columns[df.isna().sum() > 0].to_list()\n",
    "vars_missing_data"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- We need to run the pandas profiling report using only the var_missing_data variable:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if vars_missing_data:\n",
    "   pandas_report = ProfileReport(df=df[vars_missing_data], minimal=True)\n",
    "   pandas_report.to_notebook_iframe()\n",
    "else:\n",
    "   print(\"Done, conclusion? There are no variables that are missing data.\")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "____"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Correlation and PPS Analysis\n",
    "\n",
    "- In this section we would like to understand how the target variable, SalePrice, correlates with the features.\n",
    "- The below code will be from PPS lesson, to help me build the heat maps for pearson and spearman correlation, as well as a PPS heatmap. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import ppscore as pps\n",
    "\n",
    "%matplotlib inline\n",
    "\n",
    "def heatmap_corr(df, threshold, figsize=(20,12), font_annot = 8):\n",
    "  if len(df.columns) > 1:\n",
    "    mask = np.zeros_like(df, dtype=bool)\n",
    "    mask[np.triu_indices_from(mask)] = True\n",
    "    mask[abs(df) < threshold] = True\n",
    "\n",
    "    fig, axes = plt.subplots(figsize=figsize)\n",
    "    sns.heatmap(df, annot=True, xticklabels=True, yticklabels=True,\n",
    "                mask=mask, cmap='viridis', annot_kws={\"size\": font_annot}, ax=axes,\n",
    "                linewidth=0.5\n",
    "                     )\n",
    "    axes.set_yticklabels(df.columns, rotation = 0)\n",
    "    plt.ylim(len(df.columns),0)\n",
    "    plt.show()\n",
    "\n",
    "\n",
    "def heatmap_pps(df, threshold, figsize=(20,12), font_annot = 8):\n",
    "    if len(df.columns) > 1:\n",
    "\n",
    "      mask = np.zeros_like(df, dtype=bool)\n",
    "      mask[abs(df) < threshold] = True\n",
    "\n",
    "      fig, ax = plt.subplots(figsize=figsize)\n",
    "      ax = sns.heatmap(df, annot=True, xticklabels=True, yticklabels=True,\n",
    "                       mask=mask,cmap='rocket_r', annot_kws={\"size\": font_annot},\n",
    "                       linewidth=0.05, linecolor='grey')\n",
    "      \n",
    "      plt.ylim(len(df.columns),0)\n",
    "      plt.show()\n",
    "\n",
    "\n",
    "\n",
    "def CalculateCorrAndPPS(df):\n",
    "  df_corr_spearman = df.corr(method=\"spearman\")\n",
    "  df_corr_pearson = df.corr(method=\"pearson\")\n",
    "\n",
    "  pps_matrix_raw = pps.matrix(df)\n",
    "  pps_matrix = pps_matrix_raw.filter(['x', 'y', 'ppscore']).pivot(columns='x', index='y', values='ppscore')\n",
    "\n",
    "  pps_score_stats = pps_matrix_raw.query(\"ppscore < 1\").filter(['ppscore']).describe().T\n",
    "  print(\"PPS threshold - check PPS score IQR to decide threshold for heatmap \\n\")\n",
    "  print(pps_score_stats.round(3))\n",
    "\n",
    "  return df_corr_pearson, df_corr_spearman, pps_matrix\n",
    "\n",
    "\n",
    "def DisplayCorrAndPPS(df_corr_pearson, df_corr_spearman, pps_matrix, CorrThreshold, PPS_Threshold,\n",
    "                      figsize=(20,12), font_annot=8 ):\n",
    "\n",
    "  print(\"\\n\")\n",
    "  print(\"* Here I can analyze how the target variable for your ML models are correlated with other variables (features and target)\")\n",
    "  print(\"* Analyze multi colinearity, that is, how the features are correlated among themselves\")\n",
    "\n",
    "  print(\"\\n\")\n",
    "  print(\"*** Heatmap: Spearman Correlation ***\")\n",
    "  print(\"It evaluates monotonic relationships between variables \\n\")\n",
    "  heatmap_corr(df=df_corr_spearman, threshold=CorrThreshold, figsize=figsize, font_annot=font_annot)\n",
    "\n",
    "  print(\"\\n\")\n",
    "  print(\"*** Heatmap: Pearson Correlation ***\")\n",
    "  print(\"It evaluates the linear relationship between two continuous variables \\n\")\n",
    "  heatmap_corr(df=df_corr_pearson, threshold=CorrThreshold, figsize=figsize, font_annot=font_annot)\n",
    "\n",
    "  print(\"\\n\")\n",
    "  print(\"*** Heatmap: Power Predictive Score (PPS) ***\")\n",
    "  print(f\"PPS detects linear or non-linear relationships between two columns.\\n\"\n",
    "        f\"The score ranges from 0 (no predictive power) to 1 (perfect predictive power) \\n\")\n",
    "  heatmap_pps(df=pps_matrix,threshold=PPS_Threshold, figsize=figsize, font_annot=font_annot)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Calculate the correlations and power predictive score:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_corr_pearson, df_corr_spearman, pps_matrix = CalculateCorrAndPPS(df)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- The table above shows the most common levels for pps scores in the matrix. The majority are between 0 and 066.\n",
    "\n",
    "\n",
    "Further more we will display the correlation and pps results on the Heat Maps: "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "DisplayCorrAndPPS(df_corr_pearson = df_corr_pearson,\n",
    "                  df_corr_spearman = df_corr_spearman, \n",
    "                  pps_matrix = pps_matrix,\n",
    "                  CorrThreshold = 0.6, PPS_Threshold = 0.2,\n",
    "                  figsize=(12,10), font_annot=10)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "___"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Dataset Analysis\n",
    "\n",
    "### Data Exploration:\n",
    "\n",
    "- The data presented in these reports shows that there are fields that contain many zero values, more concerning though, is the number of variables that do not contain data. ie. contain null values. \n",
    "\n",
    "    - I will further examine these variables and explore whether there is a common criteria that may assist in imputing data into these variables or whether in some case it is viable to drop the feature completely. \n",
    "    - I will then do a correlation study and compare the before and after results to establish whether this excise makes a difference to predicting sale price. \n",
    "\n",
    "\n",
    "### Correlation and PPS Analysis.\n",
    "\n",
    "- We should have in mind that the results show a number of variables to be moderated to strong predictors for other variables, most \n",
    "asynchronously. However, I am highly interested in variables that are predictors of the sale price.\n",
    "\n",
    "    - From the results of both the correlation and PPS studies, I see that the strongest predictor of sale price (SalePrice) is Overall Quality (OverallQual) of the property. \n",
    "    - Overall the correlation study shows 6 features that are positively and strongly correlated to SalePrice:\n",
    "        - 1stFlorSF (first floor square foot)\n",
    "        - GarageArea (garage area measured in square foot)\n",
    "        - GrLivArea (ground floor living area)\n",
    "        - OverallQual (Overall quality of materials used)\n",
    "        - TotalBsmtSF (The total of basement measured in sq. ft.)\n",
    "        - YearBuilt (The year when the house was built)\n",
    "\n",
    "\n",
    "DataCleaningEffect() taken from ML Feature Engine Unit 9: Custom Functions.\n",
    "\n",
    "-  Function objective: assess the effect of the cleaning data when:\n",
    "    - input mean, median aor arbitrary number is a numerical variable.\n",
    "    - Replace with 'Missing' or most frequent a categorical variable.\n",
    "- Parameters: \n",
    "    - df_original: data not being cleaned. \n",
    "    - df_cleaned: data being cleaned.\n",
    "    - variables_applied_with_method: variables where i have applied a given method.\n",
    "\n",
    "\n",
    "- It is understandable if, at first, the below code seems a little complicated, at this point we try to make sense of the pseud-code and understand the function parameters.  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import seaborn as sns\n",
    "sns.set(style=\"whitegrid\")\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "def DataCleaningEffect(df_original,df_cleaned,variables_applied_with_method):\n",
    "\n",
    "  flag_count=1 # Indicate the plot number\n",
    "  \n",
    "  # Distinguish between numerical and categorical variables\n",
    "  categorical_variables = df_original.select_dtypes(exclude=['number']).columns \n",
    "\n",
    "  # scan over the variables, \n",
    "    # first on variables that you applied to the method\n",
    "    # if the variable is numerical plot a histogram, if categorical plot a barplot\n",
    "  for set_of_variables in [variables_applied_with_method]:\n",
    "    print(\"\\n=====================================================================================\")\n",
    "    print(f\"* Distribution Effect Analysis After Data Cleaning Method in the following variables:\")\n",
    "    print(f\"{set_of_variables} \\n\\n\")\n",
    "  \n",
    "\n",
    "    for var in set_of_variables:\n",
    "      if var in categorical_variables:  # it is categorical variable: barplot\n",
    "        \n",
    "        df1 = pd.DataFrame({\"Type\":\"Original\",\"Value\":df_original[var]})\n",
    "        df2 = pd.DataFrame({\"Type\":\"Cleaned\",\"Value\":df_cleaned[var]})\n",
    "        dfAux = pd.concat([df1, df2], axis=0)\n",
    "        fig , axes = plt.subplots(figsize=(15, 5))\n",
    "        sns.countplot(hue='Type', data=dfAux, x=\"Value\",palette=['#432371',\"#FAAE7B\"])\n",
    "        axes.set(title=f\"Distribution Plot {flag_count}: {var}\")\n",
    "        plt.xticks(rotation=90)\n",
    "        plt.legend() \n",
    "\n",
    "      else: # it is numerical variable: histogram\n",
    "\n",
    "        fig , axes = plt.subplots(figsize=(10, 5))\n",
    "        sns.histplot(data=df_original, x=var, color=\"#432371\", label='Original', kde=True,element=\"step\", ax=axes)\n",
    "        sns.histplot(data=df_cleaned, x=var, color=\"#FAAE7B\", label='Cleaned', kde=True,element=\"step\", ax=axes)\n",
    "        axes.set(title=f\"Distribution Plot {flag_count}: {var}\")\n",
    "        plt.legend() \n",
    "\n",
    "      plt.show()\n",
    "      flag_count+= 1\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "___"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data Cleaning\n",
    "\n",
    "### Assessing the missing data levels from our dataset.\n",
    "\n",
    "- We need to custom the function so this can show us the missing data levels in a data frame. \n",
    "    - Absolute levels.\n",
    "    - Relative levels\n",
    "    - Data type."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def EvaluateMissingData(df):\n",
    "  missing_data_absolute = df.isnull().sum()\n",
    "  missing_data_percentage = round(missing_data_absolute/len(df)*100 , 2)\n",
    "  df_missing_data = (pd.DataFrame(\n",
    "                          data= {\"RowsWithMissingData\": missing_data_absolute,\n",
    "                                 \"PercentageOfDataset\": missing_data_percentage,\n",
    "                                 \"DataType\":df.dtypes}\n",
    "                                  )\n",
    "                    .sort_values(by=['PercentageOfDataset'],ascending=False)\n",
    "                    .query(\"PercentageOfDataset > 0\")\n",
    "                    )\n",
    "\n",
    "  return df_missing_data"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- We have to evaluate the missing data:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "EvaluateMissingData(df)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- After the evaluation we can see the variables listed with the missing data.\n",
    "- Therefore we will drop the Enclosed Porch and WoodDeckSF as there are more then 89.38, respectively 90.68 percent of null values.\n",
    "- Other fields may possibly be imputed with a valid value or median.\n",
    "\n",
    "*As we can see the 6 features that show positively and strongly correlation to the sale price of each house are not listed among these variables that contain null values.*\n",
    "\n",
    "The 6 features that show positively correlation to the sale price are:\n",
    "    - 1stFlrSF,\n",
    "    - GarageArea,\n",
    "    - GrLivArea,\n",
    "    - OverallQuall,\n",
    "    - TotalBsmtSF,\n",
    "    - YearBuilt."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**At this point it is important to have a copy of the house price records data frame:**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_clean = df.copy()\n",
    "print(df_clean.shape)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "___"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Train and Test\n",
    "\n",
    "- It is very important to split the dataset in 2 parts, so we will be able to test and train the ML.\n",
    "    - It is also very important to split those in almost equal parts so we won't end up with not having enough data to train or test."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "train_set, test_set, _, __ = train_test_split(\n",
    "                                        df,\n",
    "                                        df['SalePrice'],\n",
    "                                        test_size=0.2,\n",
    "                                        random_state=0)\n",
    "\n",
    "print(f\"train_set shape: {train_set.shape} \\ntest_set shape: {test_set.shape}\")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "After we have split the dataset in the train set (1168, 24) and test_set (292, 24), we have to evaluate the missing values from train_set."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_missing_data = EvaluateMissingData(train_set)\n",
    "print(f\"* There are {df_missing_data.shape[0]} variables with missing data \\n\")\n",
    "df_missing_data"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- After the evaluation from train_set, looks like there are 9 variables in total with missing data.\n",
    "- Therefore, we will further investigate the 2 with a higher percentage of missing data.\n",
    "    - EnclosedPorch (90.41%)\n",
    "    - WoodDeckSF (88.53%)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_wooddecksf = train_set.loc[train_set['WoodDeckSF'].notnull()]\n",
    "df_wooddecksf[['WoodDeckSF', 'SalePrice']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_wooddecksf['WoodDeckSF'].value_counts().sort_index(ascending=False).head(10)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### EnclosedPorch - Enclosed porch area in square feet.\n",
    "\n",
    "- During the evaluation of the missing data, we can clearly see that this variable contains more them 90% null values. (90.41%).\n",
    "- According with the evaluation, we consider that this element won't be adding any value to the sale price.\n",
    "- As the houses that my niece plans to buy do not have an enclosed porch I consider this element to be with no power of predictive sale price."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### WoodDeckSF - Wood deck area in square feet.\n",
    "\n",
    "- During the evaluation of the missing data, we can clearly see that this variable contains more then 88% null values. (88.53%).\n",
    "- According with the evaluation, we consider that this element won't be adding any value to the sale price.\n",
    "- As the houses that my niece plans to buy do not add enough uniques to the houses, also the houses have to be refurbished before sale. \n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Furthermore, I consider that the correlation and PPS analysis shows that these fields have no predictive power."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Conclusion\n",
    "\n",
    "Having in mind the above mentioned factors we consider that EnclosedPorch and WoodDeckSF add no value to the sale price, therefore we will be dropping this 2 factors.\n",
    "\n",
    "- In order to drop these 2 factors we will be using the 'feature_engine's DropFeatures' method. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from feature_engine.selection import DropFeatures\n",
    "variables = ['EnclosedPorch', 'WoodDeckSF']\n",
    "imputer = DropFeatures(features_to_drop=variables)\n",
    "imputer.fit(train_set)\n",
    "train_set, test_set = imputer.transform(train_set), imputer.transform(test_set)\n",
    "train_set.head()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We will clean the dataset for the refurbished houses as well."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_clean = imputer.transform(df_clean)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "null_variables = train_set.columns[train_set.isnull().any()].tolist()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "___"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Variables to consider transforming or imputing.\n",
    "\n",
    "- Inspect the LotFrontage and MasVnrArea variables."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- LotFrontage:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_set['LotFrontage'].value_counts().sort_index(ascending=False).head(10)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- MasVnrArea:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_set['MasVnrArea'].value_counts().sort_index(ascending=False).head(10)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- The PPS score on the above variables (LotFrontage and MasVnrArea), shows that these fields have no predictive power.\n",
    "- The correlation study shows they have a moderate correlation to the sale price.\n",
    "- On inspecting the dataset, for these variables, it is noted that in relation to other variables there is no way of identifying or deriving possible valid values for imputing on null variables. \n",
    "\n",
    "### In conclusion:\n",
    "\n",
    "- Use MeanMedianImputer to impute a median value into the null variables:\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from feature_engine.imputation import MeanMedianImputer\n",
    "variables = ['LotFrontage', 'MasVnrArea']\n",
    "imputer = MeanMedianImputer(imputation_method='median', variables=variables)\n",
    "imputer.fit(train_set)\n",
    "train_set, test_set = imputer.transform(train_set), imputer.transform(test_set)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_clean = imputer.transform(df_clean)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "EvaluateMissingData(train_set)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- We can clearly see that after conducting our investigation and eliminating EnclosedPorch, WoodDeckSF and imputing null variables for LotFrontage and MasVnrArea they are not longer presented on our list.\n",
    "\n",
    "- Further more, we will investigate the left elements to see their importance in the sale price. "
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2ndFlrSf - Second floor square feet.\n",
    "\n",
    "- Inspecting the 2ndFlrSF variable: "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_set['2ndFlrSF'].value_counts().sort_index()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- As stated above in the evaluating missing data, the 2nd floor square foot has 60 variables of 1168 which contain null variables.\n",
    "- After a closer look at the dataset, it appears that if there is not a second floor, the value would be set to 0.\n",
    "    - More then 50% of values for this variable is 0. Therefore, we deduce imputing the null values with 0 would add value to our dataset. \n",
    "- We prepare the pipeline to use ArbitraryNumberImputer to input 0 into the null variables. "
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### BedroomAbvGr - Bedrooms above grade (dose NOT include basement bedrooms)\n",
    "\n",
    "- Inspecting the BedroomAbvGr:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_set['BedroomAbvGr'].value_counts().sort_index()\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- 80 variables of 1168 contains null values.\n",
    "- Looking at the values we could see that there are only 4 records in our data set that contain 0 for bedrooms that are not included in basement. \n",
    "- As all the proprieties that my niece will refurbish contain values above 0, imputing the null values with 0 will not have an effect on the sales price analysis. \n",
    "- Furthermore, we will prepare the pipeline to use ArbitraryNumberImputer to input 0 into the null variables. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pipeline = Pipeline([( '2ndFlrSF',  ArbitraryNumberImputer(arbitrary_number=0, variables=['2ndFlrSF', 'BedroomAbvGr']))])\n",
    "pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pipeline.fit(train_set)\n",
    "train_set, test_set = pipeline.transform(train_set), pipeline.transform(test_set)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_clean = pipeline.transform(df_clean)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "EvaluateMissingData(train_set)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- After adjusting the pipeline we can see that 2ndFlrSF and BedroomAbvGr no longer appear on our list.\n",
    "\n",
    "- Now we will investigate the BsmtFinType1."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### BsmtFinType1 - Rating of basement finished area.\n",
    "\n",
    "- Inspecting BsmtFinType1 variable:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_set['BsmtFinType1'].value_counts().sort_index()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Inspect BsmtExposure variable:\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_set['BsmtExposure'].value_counts().sort_index()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "train_set[train_set['BsmtFinType1'].isna()].query('BsmtExposure==\"None\"').sort_values(by=['BsmtExposure'])\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- 89 variables of 1168 contains null values.\n",
    "- After inspecting the dataset, we will be able to see that there are only 25 properties with no basement.\n",
    "- BsmtExposure however contains no null variables and on comparing the two fields i established that there are only 3 rows that are set to None.\n",
    "\n",
    "- For these 3 rows the BsmtFinType1 variable can bee imputed with None."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "query_condition = (train_set.BsmtExposure == 'None') & (train_set['BsmtFinType1'].isnull())\n",
    "train_set['BsmtFinType1'] = np.where(query_condition, 'None', train_set['BsmtFinType1'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "query_condition = (test_set.BsmtExposure == 'None') & (test_set['BsmtFinType1'].isnull())\n",
    "test_set['BsmtFinType1'] = np.where(query_condition, 'None', test_set['BsmtFinType1'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "query_condition = (df_clean.BsmtExposure == 'None') & (df_clean['BsmtFinType1'].isnull())\n",
    "df_clean['BsmtFinType1'] = np.where(query_condition, 'None', df_clean['BsmtFinType1'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_set[train_set['BsmtFinType1'].isna()].query('BsmtExposure==\"None\"').sort_values(by=['BsmtExposure'])"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- After the 3 rows have been imputed the value None, we are able to see that they are no longer appearing."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_set['BsmtFinType1'].isna().sum()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- We could see that there are still 86 BsmtFinType1 with a value of null.\n",
    "\n",
    "- Furthermore, we will be inspecting BsmtFinSF1 variable. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_temp = train_set[train_set['BsmtFinType1'].isna()].query('BsmtFinSF1==0').sort_values(by=['BsmtFinSF1'])\n",
    "print(df_temp.shape)\n",
    "df_temp"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Moving forward, we will be looking at BsmtFinSF1 which contains no null variables.\n",
    "- I conducted a search and we could see that BsmtFinType1 has nulls and BsmtFinSF1 with value 0. In conclusion there are 0 finished squared feet, which means unfinished. \n",
    "\n",
    "- We have founded that there are BsmtFinType1 has 27 Unf, this means that 27 BsmtFinType1 is actually unfinished. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "query_condition = (train_set.BsmtFinSF1 == 0) & (train_set['BsmtFinType1'].isnull())\n",
    "train_set['BsmtFinType1'] = np.where(query_condition, 'Unf', train_set['BsmtFinType1'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "query_condition = (test_set.BsmtFinSF1 == 0) & (test_set['BsmtFinType1'].isnull())\n",
    "test_set['BsmtFinType1'] = np.where(query_condition, 'Unf', test_set['BsmtFinType1'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "query_condition = (df_clean.BsmtFinSF1 == 0) & (df_clean['BsmtFinType1'].isnull())\n",
    "df_clean['BsmtFinType1'] = np.where(query_condition, 'Unf', df_clean['BsmtFinType1'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_set[train_set['BsmtFinType1'].isna()].query('BsmtFinSF1==0').sort_values(by=['BsmtFinSF1']).shape"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- The 27 rows have been imputed with Unf, now those are not longer present in our dataset. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_set['BsmtFinType1'].isna().sum()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Looks like there are still 59 BsmtFinType1 containing a null variable.\n",
    "- These remaining null variables will be imputed with Unk which means Unknown. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "imputer = CategoricalImputer(imputation_method='missing',fill_value='Unk',\n",
    "                             variables='BsmtFinType1')\n",
    "\n",
    "imputer.fit(train_set)\n",
    "train_set, test_set, df_clean = imputer.transform(train_set), imputer.transform(test_set), imputer.transform(df_clean)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_set['BsmtFinType1'].isna().sum()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- After imputing the Unk variables, there are no longer null values of BsmtFinType1."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Garage Finish - Interior finish of the garage\n",
    "\n",
    "- Inspecting the GarageFinish Variable."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_set['GarageFinish'].isna().sum()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Looks like there are 131 variables that are null for GarageFinish variable. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_set['GarageFinish'].value_counts().sort_index()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_set.loc[train_set.GarageFinish==\"None\",'GarageArea'].value_counts()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- After imputing GarageFinish==\"None\", meaning that the GarageFinish has been imputed with value None, the result is 0. There are no longer GarageArea."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_set.loc[train_set.GarageFinish.isnull(),'GarageArea'].value_counts()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- As the GarageFinish is null we are able to check if GarageArea is 0 and if so we can impute None on GarageFinish.\n",
    "- Based on the above query, only 5 rows will be affected. \n",
    "- For the remaining records we will assume that the garages are unfinished so, we will impute Unf on Garage Finish."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "query_condition = (train_set.GarageArea == 0) & (train_set['GarageFinish'].isnull())\n",
    "train_set['GarageFinish'] = np.where(query_condition, 'None', train_set['GarageFinish'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "query_condition = (test_set.GarageArea == 0) & (test_set['GarageFinish'].isnull())\n",
    "test_set['GarageFinish'] = np.where(query_condition, 'None', test_set['GarageFinish'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "query_condition = (df_clean.GarageArea == 0) & (df_clean['GarageFinish'].isnull())\n",
    "df_clean['GarageFinish'] = np.where(query_condition, 'None', df_clean['GarageFinish'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_set['GarageFinish'].isna().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pipeline = Pipeline([\n",
    "      ( 'categorical_imputer', CategoricalImputer(imputation_method='missing',\n",
    "                                                  fill_value='Unf',\n",
    "                                                  variables=['GarageFinish']) )\n",
    "])\n",
    "pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pipeline.fit(train_set)\n",
    "\n",
    "train_set, test_set = pipeline.transform(train_set), pipeline.transform(test_set)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_clean = pipeline.transform(df_clean)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_set['GarageFinish'].isna().sum()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- After imputing the Unf on GarageFinish, we can see that there are no null values for GarageFinish. "
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### GarageYrBlt - The year when the garage was built.\n",
    "\n",
    "- Inspecting the GarageYrBlt variable."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_set['GarageYrBlt'].isna().sum()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- We have got the row count where GarageYrBlt is null, and return the value of GarageFinish."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_set.loc[train_set.GarageYrBlt.isnull(),'GarageFinish'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_set[train_set.GarageFinish=='None']"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- We have to keep in mind that 58 null records are presented for the GarageYrBlt variable.\n",
    "    - If the GarageYrBlt is null that means that the variable GarageFinish will be automatically none. This means that the property doesn't have a garage. \n",
    "- We will prepare the pipeline to use ArbitraryNumberImputer to impute 0 into the null variables:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pipeline = Pipeline([\n",
    "      ( 'GarageYrBlt',  ArbitraryNumberImputer(arbitrary_number=0,\n",
    "                                                variables='GarageYrBlt') )\n",
    "])\n",
    "pipeline\n",
    "\n",
    "pipeline.fit(train_set)\n",
    "train_set, test_set = pipeline.transform(train_set), pipeline.transform(test_set)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_clean = pipeline.transform(df_clean)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Now we have to see the missing data evaluation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "EvaluateMissingData(train_set)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "EvaluateMissingData(df_clean)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- We can breath normally, as there are no longer variables missing data."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "___"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Before and after comparison.\n",
    "\n",
    "We now have to assess the effect on the variables distribution.\n",
    "\n",
    "- The function plots in the same axes the distribution before and after applying the method.\n",
    "- Now we will be able to see how different our variables would look after cleaning the data.\n",
    "- We can notice a peak in the variable distribution after median imputation. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "DataCleaningEffect(df_original=df,\n",
    "                   df_cleaned=df_clean,\n",
    "                   variables_applied_with_method=null_variables)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "___"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Datatype changes - Float to integer.\n",
    "\n",
    "- After examining tha data in the refurbished houses, we will be able to see that there are no float values in the float columns so we will change these into integers. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(df_clean.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_clean.select_dtypes('float').info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for col in df_clean.select_dtypes('float').columns:\n",
    "    df_clean[col] = df_clean[col].astype('int64')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_clean.select_dtypes('float').info()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "On examining the data in the refurbished houses, we can see that there are no float values. So we will change these into int."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for col in df_refurbished.select_dtypes('float').columns:\n",
    "    df_refurbished[col] = df_refurbished[col].astype('Int64')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_refurbished.select_dtypes('float').info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_refurbished.info()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "___"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Change float columns to int for train and test."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_set.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for col in train_set.select_dtypes('float').columns:\n",
    "    train_set[col] = train_set[col].astype('int64')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for col in test_set.select_dtypes('float').columns:\n",
    "    test_set[col] = test_set[col].astype('int64')"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "___"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Save the training and test sets to csv."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Create a cleaned folder:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "try:\n",
    "  os.makedirs(name='outputs/datasets/cleaned') # create outputs/datasets/collection folder\n",
    "except Exception as e:\n",
    "  print(e)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- output the clean datasets to csv files into the outputs/datasets folder\n",
    "- outputs/datasets/cleaned/train_set.csv\n",
    "- outputs/datasets/cleaned/test_set.csv\n",
    "- outputs/datasets/cleaned/clean_house_price_records.csv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_set.to_csv(\"outputs/datasets/cleaned/train_set.csv\", index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_set.to_csv(\"outputs/datasets/cleaned/test_set.csv\", index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_clean.to_csv(\"outputs/datasets/cleaned/clean_house_price_records.csv\", index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_refurbished.to_csv(\"outputs/datasets/cleaned/clean_refurbished_houses.csv\", index=False)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "___"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Conclusion and Next Steps"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- We have created a cleaning version of the housing price dataset and the refurbished houses datasets.\n",
    "- On the refurbished dataset the only step taken was to drop the variables EnclosedPorch and WoodDeckSf.\n",
    "- The housing price were saved to csv files in the outputs/datasets/cleaned folder:\n",
    "    - clean_house_price_records.csv\n",
    "    - clean_refurbished_houses.csv\n",
    "    - train_set.csv\n",
    "    - test_set.csv\n",
    "\n",
    "- Further, we will be moving on to Feature Engineering."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "___"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.12 (default, Jan 19 2023, 19:45:31) \n[GCC 9.4.0]"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "8b8334dab9339717f727a1deaf837b322d7a41c20d15cc86be99a8e69ceec8ce"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
